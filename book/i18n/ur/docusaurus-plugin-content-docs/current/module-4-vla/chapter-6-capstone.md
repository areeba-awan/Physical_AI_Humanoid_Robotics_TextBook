---
sidebar_position: 6
title: "4.6 Ú©ÛŒÙ¾Ø³Ù¹ÙˆÙ†: VLA Ø±ÙˆØ¨ÙˆÙ¹ Ù¾Ø±ÙˆØ¬ÛŒÚ©Ù¹"
description: "Ø¢ÙˆØ§Ø² Ø³Û’ Ú©Ù†Ù¹Ø±ÙˆÙ„ Ù…Ú©Ù…Ù„ ÛØ¯Ø§ÛŒØ§Øª Ù¾Ø± Ø¹Ù…Ù„ Ú©Ø±Ù†Û’ ÙˆØ§Ù„Ø§ Ø±ÙˆØ¨ÙˆÙ¹ Ø¨Ù†Ø§Ø¦ÛŒÚº"
keywords: ["Ú©ÛŒÙ¾Ø³Ù¹ÙˆÙ†", "Ù¾Ø±ÙˆØ¬ÛŒÚ©Ù¹", "VLA", "Ø±ÙˆØ¨ÙˆÙ¹", "ÛØ¯Ø§ÛŒØ§Øª Ú©ÛŒ Ù¾ÛŒØ±ÙˆÛŒ", "Ø¢ÙˆØ§Ø² Ú©Ù†Ù¹Ø±ÙˆÙ„", "Whisper"]
---

# Ø¨Ø§Ø¨ 4.6: Ú©ÛŒÙ¾Ø³Ù¹ÙˆÙ† - VLA Ø±ÙˆØ¨ÙˆÙ¹ Ù¾Ø±ÙˆØ¬ÛŒÚ©Ù¹

## Ù¾Ø±ÙˆØ¬ÛŒÚ©Ù¹ Ú©Ø§ Ø¬Ø§Ø¦Ø²Û

Ø§Ø³ Ú©ÛŒÙ¾Ø³Ù¹ÙˆÙ† Ù…ÛŒÚºØŒ Ø¢Ù¾ Ø§ÛŒÚ© Ù…Ú©Ù…Ù„ VLA Ø³Û’ Ú†Ù„Ù†Û’ ÙˆØ§Ù„Ø§ Ø±ÙˆØ¨ÙˆÙ¹ Ø¨Ù†Ø§Ø¦ÛŒÚº Ú¯Û’ Ø¬Ùˆ:

- Ù‚Ø¯Ø±ØªÛŒ Ø²Ø¨Ø§Ù† Ú©ÛŒ ÛØ¯Ø§ÛŒØ§Øª Ø³Ù…Ø¬Ú¾ Ø³Ú©Û’
- Ù…Ø§Ø­ÙˆÙ„ Ù…ÛŒÚº Ø§Ø´ÛŒØ§Ø¡ Ú©Ùˆ Ø¯ÛŒÚ©Ú¾ Ø³Ú©Û’
- ÛÛŒÙ†ÚˆÙ„Ù†Ú¯ Ú©Û’ Ú©Ø§Ù…ÙˆÚº Ú©ÛŒ Ù…Ù†ØµÙˆØ¨Û Ø¨Ù†Ø¯ÛŒ Ø§ÙˆØ± Ø¹Ù…Ù„ Ú©Ø± Ø³Ú©Û’
- Ù…Ø¸Ø§ÛØ±ÙˆÚº Ø³Û’ Ø³ÛŒÚ©Ú¾ Ø³Ú©Û’
- **ÙˆÛŒÚ© ÙˆØ±Úˆ Ø§ÛŒÚ©Ù¹ÛŒÙˆÛŒØ´Ù† Ú©Û’ Ø³Ø§ØªÚ¾ Ø¢ÙˆØ§Ø² Ú©Û’ Ø§Ø­Ú©Ø§Ù…Ø§Øª Ú©Ø§ Ø¬ÙˆØ§Ø¨ Ø¯Û’**
- **Ø¢ÙˆØ§Ø² ÙÛŒÚˆØ¨ÛŒÚ© Ø§ÙˆØ± ØªØµØ¯ÛŒÙ‚Ø§Øª ÙØ±Ø§ÛÙ… Ú©Ø±Û’**

## Ù¾Ø±ÙˆØ¬ÛŒÚ©Ù¹: Ø¢ÙˆØ§Ø² Ø³Û’ Ú©Ù†Ù¹Ø±ÙˆÙ„ Ú©Ú†Ù† Ø§Ø³Ø³Ù¹Ù†Ù¹ Ø±ÙˆØ¨ÙˆÙ¹

### Ø³Ø³Ù¹Ù… Ø¢Ø±Ú©ÛŒÙ¹ÛŒÚ©Ú†Ø±

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Ø¢ÙˆØ§Ø² Ø³Û’ Ú©Ù†Ù¹Ø±ÙˆÙ„ Ú©Ú†Ù† Ø§Ø³Ø³Ù¹Ù†Ù¹ VLA Ø³Ø³Ù¹Ù…                    â”‚
â”‚                                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    ØµØ§Ø±Ù Ø§Ù†Ù¹Ø±ÙÛŒØ³                           â”‚    â”‚
â”‚  â”‚                                                            â”‚    â”‚
â”‚  â”‚   ğŸ¤ Ø¢ÙˆØ§Ø² Ø§Ù† Ù¾Ù¹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚    â”‚
â”‚  â”‚   "Ø§Ø±Û’ Ø´ÛŒÙØŒ Ø³ÛŒØ¨ Ú©Ùˆ Ù¾ÛŒØ§Ù„Û’    â”‚                           â”‚    â”‚
â”‚  â”‚    Ù…ÛŒÚº Ø±Ú©Ú¾Ùˆ"                 â”‚                           â”‚    â”‚
â”‚  â”‚                               â”‚                           â”‚    â”‚
â”‚  â”‚   ğŸ”Š Ø¢ÙˆØ§Ø² Ø¢Ø¤Ù¹ Ù¾Ù¹ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
â”‚  â”‚   "Ø³ÛŒØ¨ Ø§Ù¹Ú¾Ø§ Ø±ÛØ§ ÛÙˆÚº..."      â”‚                    â”‚     â”‚    â”‚
â”‚  â”‚                               â”‚                    â”‚     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                  â”‚                    â”‚           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    Ø¢ÙˆØ§Ø² Ù¾Ø±ÙˆØ³ÛŒØ³Ù†Ú¯                          â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚  ÙˆÛŒÚ© ÙˆØ±Úˆ  â”‚  â”‚  Whisper   â”‚  â”‚   Ù¹ÛŒÚ©Ø³Ù¹ Ù¹Ùˆ Ø§Ø³Ù¾ÛŒÚ†  â”‚  â”‚    â”‚
â”‚  â”‚  â”‚   ÚˆÛŒÙ¹ÛŒÚ©Ø´Ù† â”‚â”€â”€â”‚    STT     â”‚  â”‚      (gTTS)        â”‚  â”‚    â”‚
â”‚  â”‚  â”‚(Porcupine) â”‚  â”‚            â”‚  â”‚                    â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                            â”‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    VLA Ø¯Ù…Ø§Øº                               â”‚    â”‚
â”‚  â”‚                                                            â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚    â”‚
â”‚  â”‚  â”‚   ÙˆÛŒÚ˜Ù†    â”‚  â”‚   Ø²Ø¨Ø§Ù†    â”‚  â”‚   Ø§ÛŒÚ©Ø´Ù†   â”‚          â”‚    â”‚
â”‚  â”‚  â”‚  Ø§Ù†Ú©ÙˆÚˆØ±   â”‚  â”‚  Ø§Ù†Ú©ÙˆÚˆØ±   â”‚  â”‚  ÚˆÛŒÚ©ÙˆÚˆØ±   â”‚          â”‚    â”‚
â”‚  â”‚  â”‚   (ViT)    â”‚  â”‚   (T5)     â”‚  â”‚   (MLP)    â”‚          â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜          â”‚    â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚    â”‚
â”‚  â”‚                         â”‚                                  â”‚    â”‚
â”‚  â”‚                  ÙÛŒÙˆÚ˜Ù† + Ø§ÛŒÚ©Ø´Ù†                            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                            â”‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    Ø±ÙˆØ¨ÙˆÙ¹ ÛØ§Ø±ÚˆÙˆÛŒØ¦Ø±                         â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚ Ú©ÛŒÙ…Ø±Û  â”‚  â”‚  Ø¨Ø§Ø²Ùˆ  â”‚  â”‚ Ú¯Ø±Ù¾Ø±  â”‚  â”‚  Ù…Ø§Ø¦ÛŒÚ©Ø±ÙˆÙÙˆÙ†    â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  x2    â”‚  â”‚ 7-DOF  â”‚  â”‚ 2-Ø¬Ø¨Ú‘Ø§ â”‚  â”‚  + Ø§Ø³Ù¾ÛŒÚ©Ø±     â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Ù…Ø±Ø­Ù„Û 1: Ø§Ù†ÙˆØ§Ø¦Ø±Ù†Ù…Ù†Ù¹ Ø³ÛŒÙ¹ Ø§Ù¾

### Ø§ÛŒØ²ÛŒÚ© Ø³ÛŒÙ… Ø³ÛŒÙ†

```python
# capstone/setup_kitchen.py
from omni.isaac.core import Ø¯Ù†ÛŒØ§
from omni.isaac.manipulators import SingleManipulator

def setup_kitchen():
    world = World()

    # Ø±ÙˆØ¨ÙˆÙ¹ Ø´Ø§Ù…Ù„ Ú©Ø±ÛŒÚº
    robot = world.scene.add(
        SingleManipulator(
            prim_path="/World/FrankaKitchen",
            usd_path="/Isaac/Robots/Franka/franka.usd"
        )
    )

    # Ú©Ú†Ù† Ú©ÛŒ Ø§Ø´ÛŒØ§Ø¡ Ø´Ø§Ù…Ù„ Ú©Ø±ÛŒÚº
    items = [
        ("apple", "/assets/apple.usd", [0.3, 0.0, 0.02]),    # Ø³ÛŒØ¨
        ("bowl", "/assets/bowl.usd", [0.4, 0.2, 0.0]),       # Ù¾ÛŒØ§Ù„Û
        ("cup", "/assets/cup.usd", [0.2, -0.2, 0.0]),        # Ú©Ù¾
        ("plate", "/assets/plate.usd", [0.5, 0.0, 0.0]),     # Ù¾Ù„ÛŒÙ¹
    ]

    for name, usd, pos in items:
        world.scene.add_usd_to_stage(usd, f"/World/{name}")

    return world, robot
```

## Ù…Ø±Ø­Ù„Û 2: VLA Ù…Ø§ÚˆÙ„

### Ù…Ø§ÚˆÙ„ Ø¢Ø±Ú©ÛŒÙ¹ÛŒÚ©Ú†Ø±

```python
# capstone/vla_model.py
import torch
import torch.nn as nn
from transformers import ViTModel, T5EncoderModel

class KitchenVLA(nn.Ù…ÙˆØ¯ÛŒÙˆÙ„):
    def __init__(self):
        super().__init__()

        # ÙˆÛŒÚ˜Ù† Ø§Ù†Ú©ÙˆÚˆØ±
        self.vision = ViTModel.from_pretrained('google/vit-base-patch16-224')

        # Ø²Ø¨Ø§Ù† Ø§Ù†Ú©ÙˆÚˆØ±
        self.language = T5EncoderModel.from_pretrained('t5-base')

        # ÙÛŒÙˆÚ˜Ù† Ù„ÛŒØ¦Ø±
        self.fusion = nn.MultiheadAttention(embed_dim=768, num_heads=8)

        # Ø§ÛŒÚ©Ø´Ù† ÚˆÛŒÚ©ÙˆÚˆØ±
        self.action_head = nn.Sequential(
            nn.Linear(768, 256),
            nn.ReLU(),
            nn.Linear(256, 7),  # 7-DOF Ø§ÛŒÚ©Ø´Ù†
            nn.Tanh()
        )

    def forward(self, image, instruction_tokens):
        # ÙˆÛŒÚ˜Ù† Ø§Ù†Ú©ÙˆÚˆ Ú©Ø±ÛŒÚº
        vis_features = self.vision(image).last_hidden_state

        # Ø²Ø¨Ø§Ù† Ø§Ù†Ú©ÙˆÚˆ Ú©Ø±ÛŒÚº
        lang_features = self.language(instruction_tokens).last_hidden_state

        # Ú©Ø±Ø§Ø³-Ø§Ù¹ÛŒÙ†Ø´Ù† ÙÛŒÙˆÚ˜Ù†
        fused, _ = self.fusion(
            query=vis_features,
            key=lang_features,
            value=lang_features
        )

        # Ø§ÛŒÚ©Ø´Ù† ÚˆÛŒÚ©ÙˆÚˆ Ú©Ø±ÛŒÚº
        pooled = fused.mean(dim=1)
        action = self.action_head(pooled)

        return action
```

## Ù…Ø±Ø­Ù„Û 3: ØªØ±Ø¨ÛŒØª

### ÚˆÛŒÙ¹Ø§ Ú©Ù„ÛŒÚ©Ø´Ù†

```python
# capstone/collect_demos.py
class DemoCollector:
    def __init__(self, robot):
        self.robot = robot
        self.demos = []

    def record_demo(self, instruction):
        demo = {
            'instruction': instruction,
            'observations': [],
            'actions': []
        }

        print(f"ÚˆÛŒÙ…Ùˆ Ø±ÛŒÚ©Ø§Ø±Úˆ ÛÙˆ Ø±ÛØ§ ÛÛ’: {instruction}")
        print("Ú©Ø§Ù… Ù…Ú©Ù…Ù„ Ú©Ø±Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ø±ÙˆØ¨ÙˆÙ¹ Ú©Ùˆ Ø­Ø±Ú©Øª Ø¯ÛŒÚº...")

        while not self.task_complete():
            obs = self.get_observation()
            action = self.get_human_action()

            demo['observations'].append(obs)
            demo['actions'].append(action)

        self.demos.append(demo)
        return demo
```

### ØªØ±Ø¨ÛŒØªÛŒ Ù„ÙˆÙ¾

```python
# capstone/train.py
def train_vla(model, dataloader, epochs=100):
    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
    criterion = nn.MSELoss()

    for epoch in range(epochs):
        for batch in dataloader:
            images = batch['images']
            instructions = batch['instructions']
            target_actions = batch['actions']

            # ÙØ§Ø±ÙˆØ±Úˆ Ù¾Ø§Ø³
            pred_actions = model(images, instructions)

            # Ù„Ø§Ø³
            loss = criterion(pred_actions, target_actions)

            # Ø¨ÛŒÚ©ÙˆØ±Úˆ
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        print(f"Ø§ÛŒÙ¾Ø§Ú© {epoch}: Ù„Ø§Ø³ = {loss.item():.4f}")
```

## Ù…Ø±Ø­Ù„Û 4: Ø¢ÙˆØ§Ø² Ú©Ù†Ù¹Ø±ÙˆÙ„ Ø§Ù†Ù¹ÛŒÚ¯Ø±ÛŒØ´Ù†

### Ø¢ÙˆØ§Ø² Ú©Ù†Ù¹Ø±ÙˆÙ„ Ø³Ø³Ù¹Ù…

```python
# capstone/voice_control.py
"""Ú©Ú†Ù† Ø§Ø³Ø³Ù¹Ù†Ù¹ Ú©Û’ Ù„ÛŒÛ’ Ø¢ÙˆØ§Ø² Ú©Ù†Ù¹Ø±ÙˆÙ„ Ø³Ø³Ù¹Ù…"""

import whisper
import numpy as np
import sounddevice as sd
from gtts import gTTS
import pygame
import io
import threading
import queue

class VoiceController:
    """Ú©Ú†Ù† Ø±ÙˆØ¨ÙˆÙ¹ Ú©Û’ Ù„ÛŒÛ’ Ø¢ÙˆØ§Ø² Ú©Ù†Ù¹Ø±ÙˆÙ„"""

    def __init__(self, wake_word="Ø§Ø±Û’ Ø´ÛŒÙ"):
        # Ø§Ø³Ù¾ÛŒÚ† Ø±ÛŒÚ©Ú¯Ù†ÛŒØ´Ù†
        print("Whisper Ù…Ø§ÚˆÙ„ Ù„ÙˆÚˆ ÛÙˆ Ø±ÛØ§ ÛÛ’...")
        self.whisper = whisper.load_model("small")
        self.wake_word = wake_word.lower()

        # Ø¢ÚˆÛŒÙˆ Ø³ÛŒÙ¹Ù†Ú¯Ø²
        self.sample_rate = 16000
        self.audio_queue = queue.Queue()
        self.is_listening = True

        # Ø­Ø§Ù„Øª
        self.is_awake = False
        self.awake_timeout = 10.0  # Ø³ÛŒÚ©Ù†ÚˆØ²

        # Ø¢ÚˆÛŒÙˆ Ù¾Ù„Û’ Ø¨ÛŒÚ© Ú©Û’ Ù„ÛŒÛ’ pygame Ø´Ø±ÙˆØ¹ Ú©Ø±ÛŒÚº
        pygame.mixer.init()

    def start(self):
        """Ø¢ÙˆØ§Ø² Ú©Ù†Ù¹Ø±ÙˆÙ„ Ø³Ù†Ù†Ø§ Ø´Ø±ÙˆØ¹ Ú©Ø±ÛŒÚº"""
        self.listen_thread = threading.Thread(target=self._listen_loop)
        self.listen_thread.daemon = True
        self.listen_thread.start()
        print(f"Ø¢ÙˆØ§Ø² Ú©Ù†Ù¹Ø±ÙˆÙ„ ÙØ¹Ø§Ù„Û” Ø´Ø±ÙˆØ¹ Ú©Ø±Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ '{self.wake_word}' Ú©ÛÛŒÚºÛ”")

    def _listen_loop(self):
        """Ù…Ø³Ù„Ø³Ù„ Ø³Ù†Ù†Û’ Ú©Ø§ Ù„ÙˆÙ¾"""
        buffer = []
        silence_frames = 0

        with sd.InputStream(samplerate=self.sample_rate,
                           channels=1, dtype=np.int16,
                           blocksize=1024) as stream:
            while self.is_listening:
                audio_chunk, _ = stream.read(1024)
                audio_chunk = audio_chunk.flatten()

                # Ø¢ÙˆØ§Ø² Ú©ÛŒ Ø³Ø±Ú¯Ø±Ù…ÛŒ Ú©Ø§ Ù¾ØªÛ Ù„Ú¯Ø§Ø¦ÛŒÚº
                energy = np.abs(audio_chunk).mean()

                if energy > 300:  # Ø¢ÙˆØ§Ø² Ù…Ù„ÛŒ
                    buffer.extend(audio_chunk)
                    silence_frames = 0
                else:
                    silence_frames += 1

                # Ø®Ø§Ù…ÙˆØ´ÛŒ Ú©Û’ Ø¨Ø¹Ø¯ Ù¾Ø±ÙˆØ³ÛŒØ³ Ú©Ø±ÛŒÚº
                if silence_frames > 10 and len(buffer) > self.sample_rate:
                    audio = np.array(buffer, dtype=np.float32) / 32768.0
                    self.audio_queue.put(audio)
                    buffer = []

    def get_command(self, timeout=5.0):
        """Ø¢ÙˆØ§Ø² Ú©Ù…Ø§Ù†Úˆ Ø­Ø§ØµÙ„ Ú©Ø±ÛŒÚº (Ø¨Ù„Ø§Ú©Ù†Ú¯)"""
        try:
            audio = self.audio_queue.get(timeout=timeout)
            return self._transcribe(audio)
        except queue.Empty:
            return None

    def _transcribe(self, audio):
        """Ø¢ÚˆÛŒÙˆ Ú©Ùˆ Ù¹ÛŒÚ©Ø³Ù¹ Ù…ÛŒÚº ØªØ¨Ø¯ÛŒÙ„ Ú©Ø±ÛŒÚº"""
        result = self.whisper.transcribe(audio, language="ur")
        text = result["text"].strip().lower()

        # ÙˆÛŒÚ© ÙˆØ±Úˆ Ú©ÛŒ Ø¬Ø§Ù†Ú† Ú©Ø±ÛŒÚº
        if not self.is_awake:
            if self.wake_word in text:
                self.is_awake = True
                # ÙˆÛŒÚ© ÙˆØ±Úˆ Ú©Û’ Ø¨Ø¹Ø¯ Ú©Ù…Ø§Ù†Úˆ Ù†Ú©Ø§Ù„ÛŒÚº
                parts = text.split(self.wake_word)
                if len(parts) > 1:
                    return parts[-1].strip()
                return ""  # ØµØ±Ù ÙˆÛŒÚ© ÙˆØ±ÚˆØŒ Ú©Ù…Ø§Ù†Úˆ Ú©Ø§ Ø§Ù†ØªØ¸Ø§Ø±
            return None
        else:
            return text

    def speak(self, text):
        """Ù¹ÛŒÚ©Ø³Ù¹ Ø³Û’ Ø¢ÙˆØ§Ø² Ø¢Ø¤Ù¹ Ù¾Ù¹"""
        print(f"Ø±ÙˆØ¨ÙˆÙ¹: {text}")
        tts = gTTS(text=text, lang='ur')
        fp = io.BytesIO()
        tts.write_to_fp(fp)
        fp.seek(0)

        pygame.mixer.music.load(fp)
        pygame.mixer.music.play()
        while pygame.mixer.music.get_busy():
            pygame.time.wait(100)

    def confirm_action(self, action_description):
        """Ø§ÛŒÚ©Ø´Ù† Ú©ÛŒ ØªØµØ¯ÛŒÙ‚ Ø¨ÙˆÙ„ÛŒÚº"""
        self.speak(action_description)

    def ask_clarification(self, question):
        """ØµØ§Ø±Ù Ø³Û’ ÙˆØ¶Ø§Ø­Øª Ù…Ø§Ù†Ú¯ÛŒÚº Ø§ÙˆØ± Ø¬ÙˆØ§Ø¨ Ù„ÛŒÚº"""
        self.speak(question)
        return self.get_command(timeout=10.0)

    def stop(self):
        """Ø¢ÙˆØ§Ø² Ú©Ù†Ù¹Ø±ÙˆÙ„ Ø¨Ù†Ø¯ Ú©Ø±ÛŒÚº"""
        self.is_listening = False


class VoiceCommandParser:
    """Ø¢ÙˆØ§Ø² Ú©Û’ Ø§Ø­Ú©Ø§Ù…Ø§Øª Ú©Ùˆ Ø±ÙˆØ¨ÙˆÙ¹ Ø§ÛŒÚ©Ø´Ù†Ø² Ù…ÛŒÚº Ù¾Ø§Ø±Ø³ Ú©Ø±ÛŒÚº"""

    COMMANDS = {
        'pick': ['Ø§Ù¹Ú¾Ø§Ø¤', 'Ù¾Ú©Ú‘Ùˆ', 'Ù„Ùˆ', 'Ù„Û’ Ù„Ùˆ'],
        'place': ['Ø±Ú©Ú¾Ùˆ', 'ÚˆØ§Ù„Ùˆ', 'Ø±Ú©Ú¾ Ø¯Ùˆ'],
        'move': ['Ø¬Ø§Ø¤', 'ÛÙ„Ùˆ', 'Ú†Ù„Ùˆ'],
        'pour': ['ÚˆØ§Ù„Ùˆ', 'Ø¨Ú¾Ø±Ùˆ'],
        'stop': ['Ø±Ú©Ùˆ', 'Ø¨Ù†Ø¯ Ú©Ø±Ùˆ', 'ÙˆÙ‚ÙÛ'],
        'status': ['Ú©ÛŒØ§', 'Ú©ÛØ§Úº', 'Ø¯Ú©Ú¾Ø§Ø¤', 'Ø¨ØªØ§Ø¤'],
    }

    OBJECTS = ['Ø³ÛŒØ¨', 'Ù¾ÛŒØ§Ù„Û', 'Ú©Ù¾', 'Ù¾Ù„ÛŒÙ¹', 'Ø¨ÙˆØªÙ„', 'Ú¯Ù„Ø§Ø³', 'Ú©Ø§Ù†Ù¹Ø§', 'Ú†Ú¾Ø±ÛŒ', 'Ú†Ù…Ú†']
    LOCATIONS = ['Ù…ÛŒØ²', 'Ú©Ø§Ø¤Ù†Ù¹Ø±', 'Ø³Ù†Ú©', 'ÙØ±ÛŒØ¬', 'Ø§Ù„Ù…Ø§Ø±ÛŒ', 'Ø¨Ø§Ø¦ÛŒÚº', 'Ø¯Ø§Ø¦ÛŒÚº', 'ÛŒÛØ§Úº']

    def parse(self, command):
        """Ø¢ÙˆØ§Ø² Ú©Ù…Ø§Ù†Úˆ Ú©Ùˆ Ø³Ù¹Ø±Ú©Ú†Ø±Úˆ Ø§ÛŒÚ©Ø´Ù† Ù…ÛŒÚº Ù¾Ø§Ø±Ø³ Ú©Ø±ÛŒÚº"""
        if not command:
            return None

        command = command.lower()

        # Ø§ÛŒÚ©Ø´Ù† Ú©ÛŒ Ù‚Ø³Ù… Ú©Ø§ Ù¾ØªÛ Ù„Ú¯Ø§Ø¦ÛŒÚº
        action_type = None
        for action, keywords in self.COMMANDS.items():
            if any(kw in command for kw in keywords):
                action_type = action
                break

        if not action_type:
            return {'type': 'unknown', 'raw': command}

        # Ø§Ø´ÛŒØ§Ø¡ Ø§ÙˆØ± Ø¬Ú¯ÛÛŒÚº Ù†Ú©Ø§Ù„ÛŒÚº
        objects = [obj for obj in self.OBJECTS if obj in command]
        locations = [loc for loc in self.LOCATIONS if loc in command]

        return {
            'type': action_type,
            'objects': objects,
            'locations': locations,
            'raw': command
        }
```

### Ø¢ÙˆØ§Ø² Ø³Û’ Ú†Ù„Ù†Û’ ÙˆØ§Ù„Ø§ ROS 2 Ù†ÙˆÚˆ

```python
# capstone/voice_vla_node.py
"""Ø¢ÙˆØ§Ø² Ø³Û’ Ú©Ù†Ù¹Ø±ÙˆÙ„ VLA ROS 2 Ù†ÙˆÚˆ"""

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from std_msgs.msg import String
from trajectory_msgs.msg import JointTrajectory
from cv_bridge import CvBridge
import torch

class VoiceVLANode(Node):
    """Ú©Ú†Ù† Ø±ÙˆØ¨ÙˆÙ¹ Ú©Û’ Ù„ÛŒÛ’ Ø¢ÙˆØ§Ø² Ú©Ù†Ù¹Ø±ÙˆÙ„ ÙˆØ§Ù„Ø§ ROS 2 Ù†ÙˆÚˆ"""

    def __init__(self):
        super().__init__('voice_vla_node')

        # Ø¢ÙˆØ§Ø² Ú©Ù†Ù¹Ø±ÙˆÙ„
        self.voice = VoiceController(wake_word="Ø§Ø±Û’ Ø´ÛŒÙ")
        self.parser = VoiceCommandParser()

        # VLA Ù…Ø§ÚˆÙ„
        self.model = KitchenVLA()
        self.model.load_state_dict(torch.load('kitchen_vla.pt'))
        self.model.eval()

        # ROS Ø³ÛŒÙ¹ Ø§Ù¾
        self.bridge = CvBridge()
        self.current_image = None
        self.task_active = False

        # Ø³Ø¨Ø³Ú©Ø±Ø§Ø¦Ø¨Ø±Ø²
        self.image_sub = self.create_subscription(
            Image, '/camera/image_raw', self.image_callback, 10
        )

        # Ù¾Ø¨Ù„Ø´Ø±Ø²
        self.action_pub = self.create_publisher(
            JointTrajectory, '/joint_trajectory', 10
        )
        self.status_pub = self.create_publisher(
            String, '/robot_status', 10
        )

        # Ø¢ÙˆØ§Ø² Ú©Ù†Ù¹Ø±ÙˆÙ„ Ø´Ø±ÙˆØ¹ Ú©Ø±ÛŒÚº
        self.voice.start()
        self.voice.speak("Ú©Ú†Ù† Ø§Ø³Ø³Ù¹Ù†Ù¹ ØªÛŒØ§Ø± ÛÛ’Û” Ø­Ú©Ù… Ø¯ÛŒÙ†Û’ Ú©Û’ Ù„ÛŒÛ’ 'Ø§Ø±Û’ Ø´ÛŒÙ' Ú©ÛÛŒÚºÛ”")

        # Ø¢ÙˆØ§Ø² Ù¾Ø±ÙˆØ³ÛŒØ³Ù†Ú¯ Ù¹Ø§Ø¦Ù…Ø±
        self.create_timer(0.1, self.process_voice)

        self.get_logger().info('Voice VLA Ù†ÙˆÚˆ Ø´Ø±ÙˆØ¹ ÛÙˆ Ú¯ÛŒØ§')

    def image_callback(self, msg):
        """Ù…ÙˆØ¬ÙˆØ¯Û Ú©ÛŒÙ…Ø±Û ØªØµÙˆÛŒØ± Ù…Ø­ÙÙˆØ¸ Ú©Ø±ÛŒÚº"""
        self.current_image = self.bridge.imgmsg_to_cv2(msg, 'rgb8')

    def process_voice(self):
        """Ø¢Ù†Û’ ÙˆØ§Ù„Û’ Ø¢ÙˆØ§Ø² Ú©Û’ Ø§Ø­Ú©Ø§Ù…Ø§Øª Ù¾Ø±ÙˆØ³ÛŒØ³ Ú©Ø±ÛŒÚº"""
        command_text = self.voice.get_command(timeout=0.05)

        if command_text is None:
            return

        if command_text == "":
            # ÙˆÛŒÚ© ÙˆØ±Úˆ Ù…Ù„Ø§ØŒ Ú©Ù…Ø§Ù†Úˆ Ú©Ø§ Ø§Ù†ØªØ¸Ø§Ø±
            self.voice.speak("Ø¬ÛŒ ÛØ§ÚºØŸ Ú©ÛŒØ§ Ú©Ø±ÙˆÚºØŸ")
            return

        self.get_logger().info(f'Ø¢ÙˆØ§Ø² Ú©Ù…Ø§Ù†Úˆ: {command_text}')

        # Ú©Ù…Ø§Ù†Úˆ Ù¾Ø§Ø±Ø³ Ú©Ø±ÛŒÚº
        parsed = self.parser.parse(command_text)
        self.handle_command(parsed)

    def handle_command(self, parsed):
        """Ù¾Ø§Ø±Ø³ Ø´Ø¯Û Ø¢ÙˆØ§Ø² Ú©Ù…Ø§Ù†Úˆ Ø³Ù†Ø¨Ú¾Ø§Ù„ÛŒÚº"""
        if parsed['type'] == 'stop':
            self.task_active = False
            self.voice.speak("Ø±Ú© Ø±ÛØ§ ÛÙˆÚº")
            return

        if parsed['type'] == 'status':
            self.report_status()
            return

        if parsed['type'] == 'unknown':
            self.voice.speak("Ù…Ø¹Ø°Ø±ØªØŒ Ø³Ù…Ø¬Ú¾ Ù†ÛÛŒÚº Ø¢ÛŒØ§Û” 'Ø³ÛŒØ¨ Ø§Ù¹Ú¾Ø§Ø¤' ÛŒØ§ 'Ù¾ÛŒØ§Ù„Û’ Ù…ÛŒÚº Ø±Ú©Ú¾Ùˆ' Ú©ÛÛŒÚºÛ”")
            return

        # Ø§Ù¹Ú¾Ø§Ù†Û’/Ø±Ú©Ú¾Ù†Û’/ÛÙ„Ù†Û’ Ú©Û’ Ø§Ø­Ú©Ø§Ù…Ø§Øª
        if parsed['type'] == 'pick':
            if not parsed['objects']:
                self.voice.speak("Ú©ÛŒØ§ Ø§Ù¹Ú¾Ø§Ø¤ÚºØŸ")
                return
            obj = parsed['objects'][0]
            self.voice.confirm_action(f"{obj} Ø§Ù¹Ú¾Ø§ Ø±ÛØ§ ÛÙˆÚº")
            self.execute_vla_task(f"{obj} Ø§Ù¹Ú¾Ø§Ø¤")

        elif parsed['type'] == 'place':
            if not parsed['locations']:
                self.voice.speak("Ú©ÛØ§Úº Ø±Ú©Ú¾ÙˆÚºØŸ")
                return
            loc = parsed['locations'][0]
            self.voice.confirm_action(f"{loc} Ù…ÛŒÚº Ø±Ú©Ú¾ Ø±ÛØ§ ÛÙˆÚº")
            self.execute_vla_task(f"{loc} Ù…ÛŒÚº Ø±Ú©Ú¾Ùˆ")

        elif parsed['type'] == 'pour':
            self.voice.confirm_action("ÚˆØ§Ù„ Ø±ÛØ§ ÛÙˆÚº")
            self.execute_vla_task("Ø¨Ø±ØªÙ† Ù…ÛŒÚº ÚˆØ§Ù„Ùˆ")

    def execute_vla_task(self, instruction):
        """Ø¢ÙˆØ§Ø² ÙÛŒÚˆØ¨ÛŒÚ© Ú©Û’ Ø³Ø§ØªÚ¾ VLA Ú©Ø§Ù… Ø§Ù†Ø¬Ø§Ù… Ø¯ÛŒÚº"""
        self.task_active = True

        while self.task_active:
            if self.current_image is None:
                continue

            # VLA Ø³Û’ Ø§ÛŒÚ©Ø´Ù† Ø­Ø§ØµÙ„ Ú©Ø±ÛŒÚº
            action = self.model(
                self.preprocess_image(self.current_image),
                instruction
            )

            # Ø§ÛŒÚ©Ø´Ù† Ù¾Ø¨Ù„Ø´ Ú©Ø±ÛŒÚº
            traj_msg = self.action_to_trajectory(action)
            self.action_pub.publish(traj_msg)

            # ØªÚ©Ù…ÛŒÙ„ Ú©ÛŒ Ø¬Ø§Ù†Ú†
            if self.detect_task_complete():
                self.task_active = False
                self.voice.speak("ÛÙˆ Ú¯ÛŒØ§!")
                break

            self.get_clock().sleep_for(rclpy.duration.Duration(seconds=0.1))

    def report_status(self):
        """Ø¢ÙˆØ§Ø² Ø³Û’ Ø±ÙˆØ¨ÙˆÙ¹ Ú©ÛŒ Ø­Ø§Ù„Øª Ø¨ØªØ§Ø¦ÛŒÚº"""
        status = "Ù…ÛŒÚº Ø­Ú©Ù… Ú©Û’ Ù„ÛŒÛ’ ØªÛŒØ§Ø± ÛÙˆÚºÛ”"
        if self.task_active:
            status = "Ù…ÛŒÚº Ø§Ø¨Ú¾ÛŒ Ú©Ø§Ù… Ú©Ø± Ø±ÛØ§ ÛÙˆÚºÛ”"
        self.voice.speak(status)

    def preprocess_image(self, image):
        """Ù…Ø§ÚˆÙ„ Ú©Û’ Ù„ÛŒÛ’ ØªØµÙˆÛŒØ± Ù¾Ø±ÛŒ Ù¾Ø±ÙˆØ³ÛŒØ³ Ú©Ø±ÛŒÚº"""
        # Ø³Ø§Ø¦Ø² Ø¨Ø¯Ù„ÛŒÚºØŒ Ù†Ø§Ø±Ù…Ù„Ø§Ø¦Ø² Ú©Ø±ÛŒÚºØŒ Ù¹ÛŒÙ†Ø³Ø± Ù…ÛŒÚº ØªØ¨Ø¯ÛŒÙ„ Ú©Ø±ÛŒÚº
        import torchvision.transforms as T
        transform = T.Compose([
            T.ToPILImage(),
            T.Resize((224, 224)),
            T.ToTensor(),
            T.Normalize(mean=[0.485, 0.456, 0.406],
                       std=[0.229, 0.224, 0.225])
        ])
        return transform(image).unsqueeze(0)

    def action_to_trajectory(self, action):
        """Ù…Ø§ÚˆÙ„ Ø¢Ø¤Ù¹ Ù¾Ù¹ Ú©Ùˆ ROS Ù¹Ø±ÛŒØ¬ÛŒÚ©Ù¹Ø±ÛŒ Ù…ÛŒØ³Ø¬ Ù…ÛŒÚº ØªØ¨Ø¯ÛŒÙ„ Ú©Ø±ÛŒÚº"""
        msg = JointTrajectory()
        # ... ØªØ¨Ø¯ÛŒÙ„ÛŒ Ú©ÛŒ Ù…Ù†Ø·Ù‚
        return msg

    def detect_task_complete(self):
        """Ø¬Ø§Ù†Ú†ÛŒÚº Ú©Û Ù…ÙˆØ¬ÙˆØ¯Û Ú©Ø§Ù… Ù…Ú©Ù…Ù„ ÛÛ’"""
        # Ù†ÙØ§Ø° Ú©Ø§Ù… Ú©ÛŒ Ù‚Ø³Ù… Ù¾Ø± Ù…Ù†Ø­ØµØ±
        return False


def main(args=None):
    rclpy.init(args=args)
    node = VoiceVLANode()

    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.voice.stop()
        node.destroy_node()
        rclpy.shutdown()


if __name__ == '__main__':
    main()
```

### Ú©Ø«ÛŒØ± Ø²Ø¨Ø§Ù† Ø³Ù¾ÙˆØ±Ù¹ (Ø§Ù†Ú¯Ø±ÛŒØ²ÛŒ/Ø§Ø±Ø¯Ùˆ)

```python
# capstone/multilingual_voice.py
"""Ø§Ø±Ø¯Ùˆ Ø³Ù¾ÙˆØ±Ù¹ Ú©Û’ Ø³Ø§ØªÚ¾ Ú©Ø«ÛŒØ± Ø²Ø¨Ø§Ù† Ø¢ÙˆØ§Ø² Ú©Ù†Ù¹Ø±ÙˆÙ„"""

class MultilingualVoiceController(VoiceController):
    """Ø§Ù†Ú¯Ø±ÛŒØ²ÛŒ Ø§ÙˆØ± Ø§Ø±Ø¯Ùˆ Ø³Ù¾ÙˆØ±Ù¹ Ú©Ø±Ù†Û’ ÙˆØ§Ù„Ø§ Ø¢ÙˆØ§Ø² Ú©Ù†Ù¹Ø±ÙˆÙ„Ø±"""

    WAKE_WORDS = {
        'en': 'hey chef',
        'ur': 'Ø§Ø±Û’ Ø´ÛŒÙ',
    }

    RESPONSES = {
        'en': {
            'ready': "Kitchen assistant ready.",
            'listening': "Yes? What would you like me to do?",
            'picking': "Picking up the {}",
            'placing': "Placing in the {}",
            'done': "Done!",
            'unknown': "Sorry, I didn't understand that.",
        },
        'ur': {
            'ready': "Ú©Ú†Ù† Ø§Ø³Ø³Ù¹Ù†Ù¹ ØªÛŒØ§Ø± ÛÛ’Û”",
            'listening': "Ø¬ÛŒ ÛØ§ÚºØŸ Ú©ÛŒØ§ Ú©Ø±ÙˆÚºØŸ",
            'picking': "{} Ø§Ù¹Ú¾Ø§ Ø±ÛØ§ ÛÙˆÚº",
            'placing': "{} Ù…ÛŒÚº Ø±Ú©Ú¾ Ø±ÛØ§ ÛÙˆÚº",
            'done': "ÛÙˆ Ú¯ÛŒØ§!",
            'unknown': "Ù…Ø¹Ø°Ø±ØªØŒ Ø³Ù…Ø¬Ú¾ Ù†ÛÛŒÚº Ø¢ÛŒØ§Û”",
        }
    }

    def __init__(self, default_lang='ur'):
        super().__init__()
        self.current_lang = default_lang
        self.whisper = whisper.load_model("medium")  # Ø¨ÛØªØ± Ú©Ø«ÛŒØ± Ø²Ø¨Ø§Ù†

    def _transcribe(self, audio):
        """Ø²Ø¨Ø§Ù† Ú©ÛŒ Ø´Ù†Ø§Ø®Øª Ú©Û’ Ø³Ø§ØªÚ¾ Ù¹Ø±Ø§Ù†Ø³Ú©Ø±Ø§Ø¦Ø¨ Ú©Ø±ÛŒÚº"""
        result = self.whisper.transcribe(audio)
        detected_lang = result.get("language", "ur")

        # Ø³Ù¾ÙˆØ±Ù¹Úˆ Ø²Ø¨Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ù…ÛŒÙ¾ Ú©Ø±ÛŒÚº
        if detected_lang in ['ur', 'hi']:  # Ø§Ø±Ø¯Ùˆ/ÛÙ†Ø¯ÛŒ
            self.current_lang = 'ur'
        else:
            self.current_lang = 'en'

        text = result["text"].strip().lower()

        # Ù…ÙˆØ¬ÙˆØ¯Û Ø²Ø¨Ø§Ù† Ù…ÛŒÚº ÙˆÛŒÚ© ÙˆØ±Úˆ Ú©ÛŒ Ø¬Ø§Ù†Ú†
        wake_word = self.WAKE_WORDS.get(self.current_lang, 'Ø§Ø±Û’ Ø´ÛŒÙ')
        if wake_word in text:
            self.is_awake = True
            parts = text.split(wake_word)
            return parts[-1].strip() if len(parts) > 1 else ""

        return text if self.is_awake else None

    def speak(self, key, *args):
        """Ù…ÙˆØ¬ÙˆØ¯Û Ø²Ø¨Ø§Ù† Ù…ÛŒÚº Ø¨ÙˆÙ„ÛŒÚº"""
        responses = self.RESPONSES.get(self.current_lang, self.RESPONSES['ur'])
        text = responses.get(key, key)
        if args:
            text = text.format(*args)

        print(f"Ø±ÙˆØ¨ÙˆÙ¹ ({self.current_lang}): {text}")
        tts = gTTS(text=text, lang=self.current_lang)
        # ... Ø¢ÚˆÛŒÙˆ Ú†Ù„Ø§Ø¦ÛŒÚº
```

---

## Ù…Ø±Ø­Ù„Û 5: ROS 2 ÚˆÛŒÙ¾Ù„Ø§Ø¦Ù…Ù†Ù¹

### Ù…Ø¹ÛŒØ§Ø±ÛŒ ROS 2 Ù†ÙˆÚˆ (Ù¹ÛŒÚ©Ø³Ù¹ Ø§Ù† Ù¾Ù¹)

```python
# capstone/vla_node.py
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from std_msgs.msg import String
from trajectory_msgs.msg import JointTrajectory

class VLANode(Node):
    def __init__(self):
        super().__init__('vla_node')

        # Ù…Ø§ÚˆÙ„ Ù„ÙˆÚˆ Ú©Ø±ÛŒÚº
        self.model = KitchenVLA()
        self.model.load_state_dict(torch.load('kitchen_vla.pt'))
        self.model.eval()

        # Ø³Ø¨Ø³Ú©Ø±Ø§Ø¦Ø¨Ø±Ø²
        self.image_sub = self.create_subscription(
            Image, '/camera/image_raw', self.image_callback, 10
        )
        self.instruction_sub = self.create_subscription(
            String, '/instruction', self.instruction_callback, 10
        )

        # Ù¾Ø¨Ù„Ø´Ø±
        self.action_pub = self.create_publisher(
            JointTrajectory, '/joint_trajectory', 10
        )

        self.current_instruction = None
        self.current_image = None

    def instruction_callback(self, msg):
        self.current_instruction = msg.data
        self.execute_task()

    def execute_task(self):
        while not self.task_complete():
            # Ù…Ø§ÚˆÙ„ Ø³Û’ Ø§ÛŒÚ©Ø´Ù† Ø­Ø§ØµÙ„ Ú©Ø±ÛŒÚº
            action = self.model(self.current_image, self.current_instruction)

            # Ø§ÛŒÚ©Ø´Ù† Ù¾Ø¨Ù„Ø´ Ú©Ø±ÛŒÚº
            traj_msg = self.action_to_trajectory(action)
            self.action_pub.publish(traj_msg)

            time.sleep(0.1)
```

## Ù…Ø±Ø­Ù„Û 6: Ù¹ÛŒØ³Ù¹Ù†Ú¯

### Ù¹ÛŒØ³Ù¹ Ù…Ù†Ø¸Ø±Ù†Ø§Ù…Û’

```yaml
# capstone/test_scenarios.yaml
scenarios:
  # Ù¹ÛŒÚ©Ø³Ù¹ Ù¾Ø± Ù…Ø¨Ù†ÛŒ Ù…Ù†Ø¸Ø±Ù†Ø§Ù…Û’
  - name: "Ø³Ø§Ø¯Û Ù¾Ú© Ø§ÛŒÙ†Úˆ Ù¾Ù„ÛŒØ³"
    instruction: "Ø³ÛŒØ¨ Ú©Ùˆ Ù¾ÛŒØ§Ù„Û’ Ù…ÛŒÚº Ø±Ú©Ú¾Ùˆ"
    expected_outcome: apple_in_bowl

  - name: "Ù…Ù‚Ø§Ù…ÛŒ Ø§Ø³ØªØ¯Ù„Ø§Ù„"
    instruction: "Ú©Ù¾ Ú©Ùˆ Ù¾Ù„ÛŒÙ¹ Ú©Û’ Ù‚Ø±ÛŒØ¨ Ø±Ú©Ú¾Ùˆ"
    expected_outcome: cup_near_plate

  - name: "Ù…Ù„Ù¹ÛŒ Ø³Ù¹ÛŒÙ¾ Ù¹Ø§Ø³Ú©"
    instruction: "Ú©Ù¾ÙˆÚº Ú©Ùˆ Ø§ÙˆÙ¾Ø± Ø±Ú©Ú¾Ùˆ"
    expected_outcome: cups_stacked

  - name: "Ù…Ø¨ÛÙ… Ø­ÙˆØ§Ù„Û"
    instruction: "Ù¾Ú¾Ù„ Ø§Ù¹Ú¾Ø§Ø¤"
    expected_outcome: clarification_requested

  # Ø¢ÙˆØ§Ø² Ù¾Ø± Ù…Ø¨Ù†ÛŒ Ù…Ù†Ø¸Ø±Ù†Ø§Ù…Û’
  - name: "Ø¢ÙˆØ§Ø² ÙˆÛŒÚ© ÙˆØ±Úˆ"
    voice_input: "Ø§Ø±Û’ Ø´ÛŒÙ"
    expected_outcome: robot_listening

  - name: "Ø¢ÙˆØ§Ø² Ù¾Ú© Ú©Ù…Ø§Ù†Úˆ"
    voice_input: "Ø§Ø±Û’ Ø´ÛŒÙØŒ Ø³Ø±Ø® Ø³ÛŒØ¨ Ø§Ù¹Ú¾Ø§Ø¤"
    expected_outcome: apple_picked
    voice_confirmation: "Ø³Ø±Ø® Ø³ÛŒØ¨ Ø§Ù¹Ú¾Ø§ Ø±ÛØ§ ÛÙˆÚº"

  - name: "Ø¢ÙˆØ§Ø² Ù¾Ù„ÛŒØ³ Ú©Ù…Ø§Ù†Úˆ"
    voice_input: "Ù¾ÛŒØ§Ù„Û’ Ù…ÛŒÚº Ø±Ú©Ú¾Ùˆ"
    expected_outcome: apple_in_bowl
    voice_confirmation: "Ù¾ÛŒØ§Ù„Û’ Ù…ÛŒÚº Ø±Ú©Ú¾ Ø±ÛØ§ ÛÙˆÚº"

  - name: "Ø¢ÙˆØ§Ø² Ø³Ù¹Ø§Ù¾ Ú©Ù…Ø§Ù†Úˆ"
    voice_input: "Ø±Ú©Ùˆ"
    expected_outcome: robot_stopped
    voice_confirmation: "Ø±Ú© Ø±ÛØ§ ÛÙˆÚº"

  - name: "Ø¢ÙˆØ§Ø² Ø³Ù¹ÛŒÙ¹Ø³ Ø³ÙˆØ§Ù„"
    voice_input: "Ú©ÛŒØ§ Ù†Ø¸Ø± Ø¢ØªØ§ ÛÛ’ØŸ"
    expected_outcome: scene_description
    voice_confirmation: "Ù…Ø¬Ú¾Û’ Ù†Ø¸Ø± Ø¢ Ø±ÛØ§ ÛÛ’..."

  # Ú©Ø«ÛŒØ± Ø²Ø¨Ø§Ù† Ù…Ù†Ø¸Ø±Ù†Ø§Ù…Û’ (Ø§Ù†Ú¯Ø±ÛŒØ²ÛŒ)
  - name: "Ø§Ù†Ú¯Ø±ÛŒØ²ÛŒ ÙˆÛŒÚ© ÙˆØ±Úˆ"
    voice_input: "Hey Chef"
    expected_outcome: robot_listening_english

  - name: "Ø§Ù†Ú¯Ø±ÛŒØ²ÛŒ Ù¾Ú© Ú©Ù…Ø§Ù†Úˆ"
    voice_input: "Pick up the apple"
    expected_outcome: apple_picked
    voice_confirmation: "Picking up the apple"
```

### ØªØ´Ø®ÛŒØµ

```python
def evaluate_system(vla_node, scenarios):
    results = []

    for scenario in scenarios:
        # Ù…Ø§Ø­ÙˆÙ„ Ø±ÛŒ Ø³ÛŒÙ¹ Ú©Ø±ÛŒÚº
        reset_scene()

        # ÛØ¯Ø§ÛŒØ§Øª Ø¹Ù…Ù„ Ú©Ø±ÛŒÚº (Ø¢ÙˆØ§Ø² ÛŒØ§ Ù¹ÛŒÚ©Ø³Ù¹)
        if 'voice_input' in scenario:
            success = vla_node.process_voice_test(scenario['voice_input'])
            # Ø¢ÙˆØ§Ø² ØªØµØ¯ÛŒÙ‚ Ú©ÛŒ ØªØµØ¯ÛŒÙ‚ Ú©Ø±ÛŒÚº
            if 'voice_confirmation' in scenario:
                confirmed = verify_voice_output(scenario['voice_confirmation'])
                success = success and confirmed
        else:
            success = vla_node.execute(scenario['instruction'])

        # Ù†ØªÛŒØ¬Û Ú†ÛŒÚ© Ú©Ø±ÛŒÚº
        outcome = check_outcome(scenario['expected_outcome'])

        results.append({
            'scenario': scenario['name'],
            'success': success and outcome,
        })

    # Ø±Ù¾ÙˆØ±Ù¹
    success_rate = sum(r['success'] for r in results) / len(results)
    print(f"Ú©Ø§Ù…ÛŒØ§Ø¨ÛŒ Ú©ÛŒ Ø´Ø±Ø­: {success_rate:.1%}")

    # Ø²Ù…Ø±Û’ Ú©Û’ Ù„Ø­Ø§Ø¸ Ø³Û’ ØªÙØµÛŒÙ„
    voice_tests = [r for r in results if 'Ø¢ÙˆØ§Ø²' in r['scenario'].lower()]
    text_tests = [r for r in results if 'Ø¢ÙˆØ§Ø²' not in r['scenario'].lower()]

    print(f"Ø¢ÙˆØ§Ø² Ú©Û’ Ø§Ø­Ú©Ø§Ù…Ø§Øª: {sum(r['success'] for r in voice_tests)}/{len(voice_tests)}")
    print(f"Ù¹ÛŒÚ©Ø³Ù¹ Ú©Û’ Ø§Ø­Ú©Ø§Ù…Ø§Øª: {sum(r['success'] for r in text_tests)}/{len(text_tests)}")
```

## ÚˆÛŒÙ„ÛŒÙˆØ±ÛŒØ¨Ù„Ø² Ú†ÛŒÚ© Ù„Ø³Ù¹

### Ø¨Ù†ÛŒØ§Ø¯ÛŒ ØªÙ‚Ø§Ø¶Û’
- [ ] Ø§ÛŒØ²ÛŒÚ© Ø³ÛŒÙ… Ú©Ú†Ù† Ø§Ù†ÙˆØ§Ø¦Ø±Ù†Ù…Ù†Ù¹ Ø§Ø´ÛŒØ§Ø¡ Ú©Û’ Ø³Ø§ØªÚ¾
- [ ] ØªØ±Ø¨ÛŒØª ÛŒØ§ÙØªÛ VLA Ù…Ø§ÚˆÙ„ (Ú©Ù… Ø§Ø² Ú©Ù… 80% Ø¯Ø±Ø³ØªÚ¯ÛŒ)
- [ ] ROS 2 ÚˆÛŒÙ¾Ù„Ø§Ø¦Ù…Ù†Ù¹ Ù†ÙˆÚˆ

### Ø¢ÙˆØ§Ø² Ú©Ù†Ù¹Ø±ÙˆÙ„ ØªÙ‚Ø§Ø¶Û’
- [ ] Whisper Ù¾Ø± Ù…Ø¨Ù†ÛŒ Ø§Ø³Ù¾ÛŒÚ† Ø±ÛŒÚ©Ú¯Ù†ÛŒØ´Ù†
- [ ] ÙˆÛŒÚ© ÙˆØ±Úˆ Ø§ÛŒÚ©Ù¹ÛŒÙˆÛŒØ´Ù† ("Ø§Ø±Û’ Ø´ÛŒÙ")
- [ ] Ø¢ÙˆØ§Ø² Ú©Ù…Ø§Ù†Úˆ Ù¾Ø§Ø±Ø³Ù†Ú¯
- [ ] Ù¹ÛŒÚ©Ø³Ù¹ Ø³Û’ Ø¢ÙˆØ§Ø² ÙÛŒÚˆØ¨ÛŒÚ©
- [ ] Ø¢ÙˆØ§Ø² Ú©Ù†Ù¹Ø±ÙˆÙ„ ROS 2 Ù†ÙˆÚˆ

### ÚˆÛŒÙ…Ùˆ ØªÙ‚Ø§Ø¶Û’
- [ ] ÚˆÛŒÙ…Ùˆ ÙˆÛŒÚˆÛŒÙˆ: 5+ Ù¹ÛŒÚ©Ø³Ù¹ Ù¾Ø± Ù…Ø¨Ù†ÛŒ Ú©Ø§Ù…
- [ ] ÚˆÛŒÙ…Ùˆ ÙˆÛŒÚˆÛŒÙˆ: 5+ Ø¢ÙˆØ§Ø² Ø³Û’ Ú©Ù†Ù¹Ø±ÙˆÙ„ Ú©Ø§Ù…
- [ ] Ú©Ø«ÛŒØ± Ø²Ø¨Ø§Ù† ÚˆÛŒÙ…Ùˆ (Ø§Ø±Ø¯Ùˆ + Ø§Ù†Ú¯Ø±ÛŒØ²ÛŒ)
- [ ] ØºÙ„Ø·ÛŒ ÛÛŒÙ†ÚˆÙ„Ù†Ú¯ Ø§ÙˆØ± ÙˆØ¶Ø§Ø­Øª ÚˆÛŒÙ…Ùˆ

### Ø¯Ø³ØªØ§ÙˆÛŒØ²Ø§Øª
- [ ] ØªÚ©Ù†ÛŒÚ©ÛŒ Ø±Ù¾ÙˆØ±Ù¹
- [ ] Ø¢ÙˆØ§Ø² Ú©Ù…Ø§Ù†Úˆ Ø­ÙˆØ§Ù„Û Ú¯Ø§Ø¦ÛŒÚˆ
- [ ] ØªÙ†ØµÛŒØ¨ Ø§ÙˆØ± Ø³ÛŒÙ¹ Ø§Ù¾ ÛØ¯Ø§ÛŒØ§Øª

## Ù…Ø«Ø§Ù„ÛŒ ÚˆÛŒÙ…Ùˆ Ø§Ø³Ú©Ø±Ù¾Ù¹

```
ÚˆÛŒÙ…Ùˆ: Ø¢ÙˆØ§Ø² Ø³Û’ Ú©Ù†Ù¹Ø±ÙˆÙ„ Ú©Ú†Ù† Ø§Ø³Ø³Ù¹Ù†Ù¹ Ø±ÙˆØ¨ÙˆÙ¹
================================================

[Ø±ÙˆØ¨ÙˆÙ¹ Ø´Ø±ÙˆØ¹ ÛÙˆØªØ§ ÛÛ’]
Ø±ÙˆØ¨ÙˆÙ¹: "Ú©Ú†Ù† Ø§Ø³Ø³Ù¹Ù†Ù¹ ØªÛŒØ§Ø± ÛÛ’Û” Ø­Ú©Ù… Ø¯ÛŒÙ†Û’ Ú©Û’ Ù„ÛŒÛ’ 'Ø§Ø±Û’ Ø´ÛŒÙ' Ú©ÛÛŒÚºÛ”"

[ØµØ§Ø±Ù Ø¨ÙˆÙ„ØªØ§ ÛÛ’]
ØµØ§Ø±Ù: "Ø§Ø±Û’ Ø´ÛŒÙ"
Ø±ÙˆØ¨ÙˆÙ¹: "Ø¬ÛŒ ÛØ§ÚºØŸ Ú©ÛŒØ§ Ú©Ø±ÙˆÚºØŸ"

[ØµØ§Ø±Ù Ø­Ú©Ù… Ø¯ÛŒØªØ§ ÛÛ’]
ØµØ§Ø±Ù: "Ø³Ø±Ø® Ø³ÛŒØ¨ Ø§Ù¹Ú¾Ø§Ø¤"
Ø±ÙˆØ¨ÙˆÙ¹: "Ø³Ø±Ø® Ø³ÛŒØ¨ Ø§Ù¹Ú¾Ø§ Ø±ÛØ§ ÛÙˆÚº"
[Ø±ÙˆØ¨ÙˆÙ¹ Ø³ÛŒØ¨ Ú©ÛŒ Ø·Ø±Ù Ø¬Ø§ØªØ§ ÛÛ’ØŒ Ø§Ù¹Ú¾Ø§ØªØ§ ÛÛ’]
Ø±ÙˆØ¨ÙˆÙ¹: "Ù„Û’ Ù„ÛŒØ§!"

[ØµØ§Ø±Ù Ø§Ú¯Ù„Ø§ Ø­Ú©Ù… Ø¯ÛŒØªØ§ ÛÛ’]
ØµØ§Ø±Ù: "Ù¾ÛŒØ§Ù„Û’ Ù…ÛŒÚº Ø±Ú©Ú¾Ùˆ"
Ø±ÙˆØ¨ÙˆÙ¹: "Ù¾ÛŒØ§Ù„Û’ Ù…ÛŒÚº Ø±Ú©Ú¾ Ø±ÛØ§ ÛÙˆÚº"
[Ø±ÙˆØ¨ÙˆÙ¹ Ù¾ÛŒØ§Ù„Û’ Ú©ÛŒ Ø·Ø±Ù Ø¬Ø§ØªØ§ ÛÛ’ØŒ Ø³ÛŒØ¨ Ø±Ú©Ú¾ØªØ§ ÛÛ’]
Ø±ÙˆØ¨ÙˆÙ¹: "ÛÙˆ Ú¯ÛŒØ§!"

[ØµØ§Ø±Ù Ø³ÙˆØ§Ù„ Ù¾ÙˆÚ†Ú¾ØªØ§ ÛÛ’]
ØµØ§Ø±Ù: "Ú©ÛŒØ§ Ù†Ø¸Ø± Ø¢ØªØ§ ÛÛ’ØŸ"
Ø±ÙˆØ¨ÙˆÙ¹: "Ù…Ø¬Ú¾Û’ Ù†Ø¸Ø± Ø¢ Ø±ÛØ§ ÛÛ’: Ø³ÛŒØ¨ ÙˆØ§Ù„Ø§ Ù¾ÛŒØ§Ù„ÛØŒ Ú©Ù¾ØŒ Ø§ÙˆØ± Ù¾Ù„ÛŒÙ¹Û”"

[ØµØ§Ø±Ù Ø§Ù†Ú¯Ø±ÛŒØ²ÛŒ Ù…ÛŒÚº Ø­Ú©Ù… Ø¯ÛŒØªØ§ ÛÛ’]
ØµØ§Ø±Ù: "Hey Chef, pick up the cup"
Ø±ÙˆØ¨ÙˆÙ¹: "Picking up the cup"
[Ø±ÙˆØ¨ÙˆÙ¹ Ú©Ù¾ Ø§Ù¹Ú¾Ø§ØªØ§ ÛÛ’]
Ø±ÙˆØ¨ÙˆÙ¹: "Got it!"

[ØµØ§Ø±Ù Ø±ÙˆØ¨ÙˆÙ¹ Ø±ÙˆÚ©ØªØ§ ÛÛ’]
ØµØ§Ø±Ù: "Ø±Ú©Ùˆ"
Ø±ÙˆØ¨ÙˆÙ¹: "Ø±Ú© Ø±ÛØ§ ÛÙˆÚº"
[Ø±ÙˆØ¨ÙˆÙ¹ ØªÙ…Ø§Ù… Ø­Ø±Ú©Øª Ø±ÙˆÚ© Ø¯ÛŒØªØ§ ÛÛ’]

[ÚˆÛŒÙ…Ùˆ Ù…Ú©Ù…Ù„]
Ø±ÙˆØ¨ÙˆÙ¹: "Ú©Ú†Ù† Ø§Ø³Ø³Ù¹Ù†Ù¹ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±Ù†Û’ Ú©Ø§ Ø´Ú©Ø±ÛŒÛ!"
```

## Ù…Ø¨Ø§Ø±Ú© ÛÙˆ!

Ø¢Ù¾ Ù†Û’ ÙØ²ÛŒÚ©Ù„ AI Ø§ÙˆØ± ÛÛŒÙˆÙ…ÛŒÙ†Ø§Ø¦Úˆ Ø±ÙˆØ¨ÙˆÙ¹Ú©Ø³ Ú©ÙˆØ±Ø³ Ù…Ú©Ù…Ù„ Ú©Ø± Ù„ÛŒØ§! Ø§Ø¨ Ø¢Ù¾ Ú©Û’ Ù¾Ø§Ø³ ÛŒÛ Ù…ÛØ§Ø±ØªÛŒÚº ÛÛŒÚº:

- ROS 2 Ø±ÙˆØ¨ÙˆÙ¹ Ø³Ø³Ù¹Ù…Ø² Ø¨Ù†Ø§Ù†Ø§
- Ø³Ù…ÛŒÙˆÙ„ÛŒØ´Ù† Ù…ÛŒÚº ÚˆÛŒØ¬ÛŒÙ¹Ù„ Ù¹ÙˆØ¦Ù†Ø² Ø¨Ù†Ø§Ù†Ø§
- AI Ø³Û’ Ú†Ù„Ù†Û’ ÙˆØ§Ù„Ø§ Ù¾Ø±Ø³ÛŒÙ¾Ø´Ù† ÚˆÛŒÙ¾Ù„Ø§Ø¦ÛŒ Ú©Ø±Ù†Ø§
- ÙˆÛŒÚ˜Ù†-Ù„ÛŒÙ†Ú¯ÙˆÛŒØ¬-Ø§ÛŒÚ©Ø´Ù† Ø±ÙˆØ¨ÙˆÙ¹Ø³ Ù„Ø§Ú¯Ùˆ Ú©Ø±Ù†Ø§
- **Whisper Ú©Û’ Ø³Ø§ØªÚ¾ Ø¢ÙˆØ§Ø² Ø³Û’ Ú©Ù†Ù¹Ø±ÙˆÙ„ Ø±ÙˆØ¨ÙˆÙ¹Ø³ Ø¨Ù†Ø§Ù†Ø§**
- **Ú©Ø«ÛŒØ± Ø²Ø¨Ø§Ù† Ø±ÙˆØ¨ÙˆÙ¹ Ø§Ù†Ù¹Ø±ÙÛŒØ³Ø² Ø¨Ù†Ø§Ù†Ø§**

### Ø¢Ú¯Û’ Ú©ÛŒØ§ ÛÛ’ØŸ

- Ø§ÙˆÙ¾Ù† Ø³ÙˆØ±Ø³ Ø±ÙˆØ¨ÙˆÙ¹Ú©Ø³ Ù¾Ø±ÙˆØ¬ÛŒÚ©Ù¹Ø³ Ù…ÛŒÚº Ø­ØµÛ Ù„ÛŒÚº
- ROS Ú©Ù…ÛŒÙˆÙ†Ù¹ÛŒ Ù…ÛŒÚº Ø´Ø§Ù…Ù„ ÛÙˆÚº
- Ø§Ù…Ø¨ÙˆÚˆÛŒÚˆ AI Ù¾Ø± ØªØ­Ù‚ÛŒÙ‚ÛŒ Ù…Ù‚Ø§Ù„Û’ Ø¯Ø±ÛŒØ§ÙØª Ú©Ø±ÛŒÚº
- Ø§Ù¾Ù†Ø§ Ø¢ÙˆØ§Ø² Ø³Û’ Ú©Ù†Ù¹Ø±ÙˆÙ„ Ø±ÙˆØ¨ÙˆÙ¹ Ø¨Ù†Ø§Ø¦ÛŒÚº!
- Ø¯ÙˆØ³Ø±ÛŒ Ø²Ø¨Ø§Ù†ÙˆÚº Ø§ÙˆØ± Ø¨ÙˆÙ„ÛŒÙˆÚº Ú©Û’ Ø³Ø§ØªÚ¾ ØªØ¬Ø±Ø¨Û Ú©Ø±ÛŒÚº

### ÙˆØ³Ø§Ø¦Ù„

- [OpenAI Whisper](https://github.com/openai/whisper) - Ø§Ø³Ù¾ÛŒÚ† Ø±ÛŒÚ©Ú¯Ù†ÛŒØ´Ù†
- [OpenVLA](https://openvla.github.io/) - ÙˆÛŒÚ˜Ù†-Ù„ÛŒÙ†Ú¯ÙˆÛŒØ¬-Ø§ÛŒÚ©Ø´Ù† Ù…Ø§ÚˆÙ„Ø²
- [ROS 2 Documentation](https://docs.ros.org/en/humble/) - Ø±ÙˆØ¨ÙˆÙ¹ Ø¢Ù¾Ø±ÛŒÙ¹Ù†Ú¯ Ø³Ø³Ù¹Ù…
- [Ø§ÛŒÙ† ÙˆÛŒÚˆÛŒØ§ Ø§ÛŒØ²ÛŒÚ©](https://developer.nvidia.com/isaac-sim) - Ø±ÙˆØ¨ÙˆÙ¹ Ø³Ù…ÛŒÙˆÙ„ÛŒØ´Ù†

---

**ÛÙ…Ø§Ø±Û’ Ø³Ø§ØªÚ¾ Ø³ÛŒÚ©Ú¾Ù†Û’ Ú©Ø§ Ø´Ú©Ø±ÛŒÛ!** ğŸ¤–ğŸ“

*Ø§Ø¨ Ø¬Ø§Ø¦ÛŒÚº Ø§ÙˆØ± Ø­ÛŒØ±Øª Ø§Ù†Ú¯ÛŒØ² Ø¢ÙˆØ§Ø² Ø³Û’ Ú©Ù†Ù¹Ø±ÙˆÙ„ Ø±ÙˆØ¨ÙˆÙ¹Ø³ Ø¨Ù†Ø§Ø¦ÛŒÚº!*

